<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/128128.ico">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/3232.ico">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/1616.ico">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="https://fonts.loli.net/css?family=Noto Serif SC:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">
<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"onlyear.com","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":true,"show_result":true,"style":null},"back2top":{"enable":true,"sidebar":true,"scrollpercent":true},"bookmark":{"enable":true,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":false,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="HDFSHDFS 全称 Hadoop 分布式文件系统，其最主要的作用是作为 Hadoop 生态中各系统的存储服务。">
<meta property="og:type" content="article">
<meta property="og:title" content="Hadoop HDFS">
<meta property="og:url" content="http://onlyear.com/2020/06/03/Hadoop-HDFS/index.html">
<meta property="og:site_name" content="imarktsh的博客">
<meta property="og:description" content="HDFSHDFS 全称 Hadoop 分布式文件系统，其最主要的作用是作为 Hadoop 生态中各系统的存储服务。">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://img-blog.csdn.net/20180405231127175?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3Q4OTQ2OTAyMzA=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70#pic_center">
<meta property="og:image" content="https://img-blog.csdn.net/20180405231141874?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3Q4OTQ2OTAyMzA=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70#pic_center">
<meta property="og:image" content="https://img-blog.csdn.net/20180405231158136?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3Q4OTQ2OTAyMzA=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70#pic_center">
<meta property="og:image" content="https://img-blog.csdn.net/2018040523124496?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3Q4OTQ2OTAyMzA=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70#pic_center">
<meta property="og:image" content="https://img-blog.csdn.net/20180405231310718?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3Q4OTQ2OTAyMzA=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70#pic_center">
<meta property="og:image" content="https://img-blog.csdn.net/20180405231321209?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3Q4OTQ2OTAyMzA=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70#pic_center">
<meta property="og:image" content="https://img-blog.csdn.net/20180405231336949?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3Q4OTQ2OTAyMzA=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70#pic_center">
<meta property="og:image" content="https://img-blog.csdn.net/20180405231351917?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3Q4OTQ2OTAyMzA=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70#pic_center">
<meta property="og:image" content="https://img-blog.csdn.net/20180405231405266?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3Q4OTQ2OTAyMzA=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20200603212957479.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM2NzA1NzA1,size_16,color_FFFFFF,t_70">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20200603213040381.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM2NzA1NzA1,size_16,color_FFFFFF,t_70">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20200603213210698.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM2NzA1NzA1,size_16,color_FFFFFF,t_70">
<meta property="article:published_time" content="2020-06-03T13:36:00.000Z">
<meta property="article:modified_time" content="2020-09-28T03:56:10.000Z">
<meta property="article:author" content="imarktsh">
<meta property="article:tag" content="大数据">
<meta property="article:tag" content="Hadoop">
<meta property="article:tag" content="hdfs">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://img-blog.csdn.net/20180405231127175?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3Q4OTQ2OTAyMzA=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70#pic_center">

<link rel="canonical" href="http://onlyear.com/2020/06/03/Hadoop-HDFS/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>Hadoop HDFS | imarktsh的博客</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">imarktsh的博客</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">多沉淀 多复盘</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="reading-progress-bar"></div>
  <a role="button" class="book-mark-link book-mark-link-fixed"></a>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://onlyear.com/2020/06/03/Hadoop-HDFS/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="https://img-blog.csdnimg.cn/2020053010414625.jpg">
      <meta itemprop="name" content="imarktsh">
      <meta itemprop="description" content="明天一定学">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="imarktsh的博客">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Hadoop HDFS
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-06-03 21:36:00" itemprop="dateCreated datePublished" datetime="2020-06-03T21:36:00+08:00">2020-06-03</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-09-28 11:56:10" itemprop="dateModified" datetime="2020-09-28T11:56:10+08:00">2020-09-28</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/" itemprop="url" rel="index"><span itemprop="name">大数据</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv" style="display: none;">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span id="busuanzi_value_page_pv"></span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h2 id="HDFS"><a href="#HDFS" class="headerlink" title="HDFS"></a>HDFS</h2><p>HDFS 全称 Hadoop 分布式文件系统，其最主要的作用是作为 Hadoop 生态中各系统的存储服务。</p>
<span id="more"></span>

<p><img src="https://img-blog.csdn.net/20180405231127175?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3Q4OTQ2OTAyMzA=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70#pic_center"><br>面对大规模的数据，HDFS 在设计上满足了以下目标：</p>
<ul>
<li><strong>高度容错性</strong>： HDFS 可能由成百上千的服务器构成，任何一个组件都可能失效，因此错误检测和快速、自动的恢复时 HDFS 最核心的架构目标。</li>
<li><strong>支持大规模数据集</strong>： 运行在 HDFS 应用具有很大的数据集，它应该能提供整体上高的数据传输带宽，并能支撑数以千万计的文件。</li>
<li><strong>支持流式读取数据</strong>： HDFS 的设计更多的考虑到了数据批处理，而不是用户交互处理，比之数据访问延迟的问题，更关键的是数据访问的高吞吐量。</li>
<li><strong>简单的一致性模型</strong>： “ 一次写入多次读取”的文件访问模型简化了数据一致性的问题，并且是高吞吐量称为可能。</li>
<li><strong>移动计算而非移动数据</strong>： 一个应用的请求，离它操作的数据越近就越高效，HDFS 提供了将它们自己移动到数据附近的接口。</li>
<li><strong>异构软硬件平台间的可移植性</strong>： 平台的可移植性，方便用户也方便 HDFS 作为大规模数据应用平台的推广。</li>
</ul>
<h2 id="架构与原理"><a href="#架构与原理" class="headerlink" title="架构与原理"></a>架构与原理</h2><p><img src="https://img-blog.csdn.net/20180405231141874?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3Q4OTQ2OTAyMzA=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70#pic_center" alt="在这里插入图片描述"><br>如上图所示，HDFS 使用单一的 NameNode 节点简化了整体的设计，同时使用 Master-Slave 模式，防止 NameNode 成为单点故障，<strong>Failover Controller</strong>（故障切换器）的工作便是负责监控 NameNode 的状态与切换主从服务器。与此同时，为了能够快速从故障中恢复，每一次的数据读写删操作都会记录在 NameNode 上的 <strong>EditLog</strong> 中并同步到每个 <strong>JournalNode</strong> 节点。而 DataNode 节点则负责存储物理数据，为了应对不确定的故障，每一份数据默认被保存为 3 份，并分散在不同的 DataNode 中，而通过 <strong>Balancer</strong> 则可以平衡集群之间各节点的磁盘利用率，以防止某一个 DataNode 节点存储已满但是其它 DataNode 节点却可能为空的情况。</p>
<p>最后为了方便用户操作，HDFS 提供了 HttpFS 服务，用以通过 HTTP 方式访问 HDFS 服务的功能。默认的，你可以通过 http://[master namenode host]:50070/ 访问这个功能。</p>
<p>总的来说，HDFS 主要包含了 6 个服务，它们主要的功能如下：</p>
<ol>
<li>NameNode：负责管理文件系统的 namespace 以及客户端对文件的访问；</li>
<li>DataNode：用于管理它所在节点上的存储；</li>
<li>FailoverController：故障切换控制器，负责监控与切换 Namenode 服务；</li>
<li>JournalNode：用于存储 EditLog；</li>
<li>Balancer：用于平衡集群之间各节点的磁盘利用率；</li>
<li>HttpFS：提供 HTTP 方式访问 HDFS 的功能。</li>
</ol>
<p>通常而言，在关注 HDFS 架构时，总是关注 Namenode 和 Datanode 的架构，因为它们是 HDFS 的核心，也是客户端操作数据需要依赖的两个服务，所以再来看看 Namenode &amp; Datanode 的架构吧。</p>
<h2 id="NameNode-amp-DataNode"><a href="#NameNode-amp-DataNode" class="headerlink" title="NameNode &amp; DataNode"></a>NameNode &amp; DataNode</h2><p><img src="https://img-blog.csdn.net/20180405231158136?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3Q4OTQ2OTAyMzA=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70#pic_center" alt="在这里插入图片描述"><br>在 HDFS 中，Namenode 是 HDFS 中的<strong>主节点</strong>，用于维护和管理 Datanode 上存在的 <strong>block</strong>。它是一个高度可用的服务器，用于管理文件的 namespace 并控制客户端对文件的访问。HDFS 体系的构建方式是，用户数据永远不会驻留在 Namenode 上，<strong>数据只会驻留在 Datanode</strong> 上。</p>
<p>Namenode 的功能：</p>
<ul>
<li>它是维护和管理 Datanode 的主守护进程；</li>
<li>它记录存储在集群中的所有文件的<strong>元数据，例如 block 的位置、文件大小、权限、层次结构等</strong>。有两个文件与元数据关联：</li>
</ul>
<p><strong>FsImage：它包含自 Namenode 开始以来文件的 namespace 的完整状态</strong>；<br><strong>EditLogs：它包含最近对文件系统进行的与最新 FsImage 相关的所有修改。</strong></p>
<ul>
<li>它记录了发生在文件系统元数据上的每个更改。例如，如果一个文件在 HDFS 中被删除，Namenode 会立即在 EditLog<br>中记录这个操作。</li>
<li>它定期从集群中的所有 Datanode 接收心跳信息和 block 报告，以确保 Datanode 处于活动状态； 它保留了 HDFS<br>中所有 block 的记录以及这些 block 所在的节点；</li>
<li>它负责管理所有 block 的复制；</li>
<li>在 Datanode 失败的情况下，Namenode 会为副本选择新的 Datanode，平衡磁盘使用并管理到 Datanode<br>的通信流量。</li>
</ul>
<p>Datanode 则是 HDFS 中的从节点，与 Namenode 不同的是，Datanode 是一种商品硬件，它并不具有高质量或高可用性。Datanode 是一个将数据存储在本地文件 <strong>ext3 或 ext4 中的 block 服务器</strong>。</p>
<p>Datanode 功能：</p>
<ul>
<li>这些是丛属守护进行或在每台从属机器上运行的进程；</li>
<li>实际的数据存储在 Datanode 上；</li>
<li>执行文件系统客户端底层的读写请求；</li>
<li>定期向 Namenode 发送心跳报告 HDFS 的整体健康状况，默认频率为 3 秒。</li>
</ul>
<p>上面提到 HDFS 中的数据是以 block 的形式分散在 DataNode 中，那什么是 block ，它是如何形成的呢？</p>
<h2 id="数据块（Block）"><a href="#数据块（Block）" class="headerlink" title="数据块（Block）"></a>数据块（Block）</h2><p>通常，在任何文件系统中，都将<strong>数据存储为 block</strong> 的集合。block 是硬盘上存储数据的最不连续的位置。在 hadoop 集群中，每个 <strong>block 的默认大小为 128M</strong>（此处指 hadoop 2.x 版本，hadoop 1.x 版本为 64M），您也可以通过如下配置配置 block 的大小：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dfs.block.size 或 dfs.blocksize = 64M</span><br></pre></td></tr></table></figure>

<p>HDFS 不会将每个文件存储在配置的 block 大小的确切倍数中，比如一个 514M 的文件 example.txt，如果上图所示，假设 block 大小为默认的 128M，那么将会创建 5 个block，前 4 个 block 大小为 128M，但是最后一个 block 的大小则仅为 2M。</p>
<p>那么，为何需要将 block 的大小设置为如此大，比如 128M，而不是更小呢？</p>
<p>通常我们在谈论 HDFS 的作用的时，都会谈论到<strong>巨大的数据集</strong>，即 Terabytes 和 PB 数据，所以如果我们的 block 大小仅为 4KB，那么将会产生太多的 block，间接导致产生太多的元数据，从而使<strong>管理这些 block 和 元数据会产生巨大的开销</strong>，这样无疑会<strong>增加 Namenode</strong> 和 Datanode 的负载，尤其 Namenode 是一个中心服务器，所以这并不会是我们想要的。</p>
<h2 id="元数据"><a href="#元数据" class="headerlink" title="元数据"></a>元数据</h2><p>我们知道，Namenode 对我们来说相当的重要，如果它失败了，我们注定要失败。不过 HDFS 有对它做高可用的解决方案，高可用的方案中，如何同步状态是一个关键，所以这里再介绍一下那些保存在 Namenode 上的元数据。</p>
<p>注：以下元数据同步的方式使用的是通过JournalNode 节点同步的方式。</p>
<p>NameNode 将整个 namespace ，包括 block 到文件的映射、文件的属性等，都存储在一个称为 <strong>FsImage</strong> 的文件中，它被存放在内存以及本地文件系统中。而任何对于 namespace 元数据产生修改的操作，NameNode 都会使用一种称为 <strong>EditLog 的事务日志</strong>记录下来。例如在 HDFS 中创建一个文件，NameNode 就会在 EditLog 中插入一条记录来表示；同样的，修改文件的副本系数也将往 EditLog 插入一条记录。主 NameNode 会在本地文件系统中存储这个 EditLog，并<strong>同步到各个 JournalNode 节点</strong>上，而从 NameNode 则通过在 <strong>JournalNode 节点中读取 EditLog 来完成同步</strong>。<br><img src="https://img-blog.csdn.net/2018040523124496?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3Q4OTQ2OTAyMzA=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70#pic_center"><br>当 NameNode 启动时，它会从硬盘中读取 <strong>EditLog 和 FsImage</strong>，将所有 EditLog 中的事务作用在内存中的 FsImage 上，并将这个新版本的 FsImage 从内存中保存到本地磁盘上，然后删除旧的 EditLog，这个过程也被称为一个 <strong>checkpoint。</strong></p>
<p>那么通过 NameNode 上的元数据可以确定 block 到具体 DataNode 节点的一个映射，所以客户端在读取或者写入数据到 HDFS 时，都是先到 NameNode 上获取元数据，然后根据元数据中的地址直接与 DataNode 交互，与此同时，<strong>客户端会缓存一段时间的元数据</strong>，从而减少与 NameNode 的交互。</p>
<h2 id="数据写入原理"><a href="#数据写入原理" class="headerlink" title="数据写入原理"></a>数据写入原理</h2><p>假定系统 block 的配置大小为 128MB（默认），那么客户端将把文件 “example.txt” 分成 2 个 block - 128 MB（block A） + 128MB（block B）。</p>
<p>接下来，每当客户端将数据写入 HDFS 时，将遵循以下协议：</p>
<ul>
<li>首先，HDFS 客户端将与 NameNode 联系以获得针对两个 block（例如 block A 和 block B）的写入请求；</li>
<li>然后，NameNode 将授予客户端写入权限，并将提供最终将复制文件的 DataNode 的 IP 地址。</li>
<li>根据 HDFS 的可用性，复制因素和机架感知，DataNode IP 地址的选择纯碎是随机的。 </li>
<li>假设复制因子被设置成默认值3，那么对于每个 block，NameNode 将向客户端提供 3 个 DataNode 的 IP 地址列表。该列表对于每个 block  都是唯一的。假设分配结果如下：<br>对于 block A，列表 A = { DN 1 IP， DN 4 IP, DN 6 IP }<br>对于 block B，列表 B =｛DN 3 IP， DN 7 IP, DN 9 IP｝<br>每个 block 将被复制到 3 个不同的 DataNode 中，以保持整个集群中复制因子的一致。<br>接下来，整个数据的复制将分为 3 个阶段进行：</li>
</ul>
<ol>
<li>管道设置</li>
<li>数据流和复制</li>
<li>管道关闭与确认阶段<br><img src="https://img-blog.csdn.net/20180405231310718?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3Q4OTQ2OTAyMzA=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70#pic_center"><h3 id="1-管道设置"><a href="#1-管道设置" class="headerlink" title="1) 管道设置"></a>1) 管道设置</h3>在写入 block 之前，客户端确认每个 IP 列表中的 DataNode 是否准备好接受数据，这样做时，客户端会通过连接该 block 列表中的各个 DataNode，为每个 block 创建一个管道。比如 block A，它提供的 DataNode 列表是：<br>列表 A = { DN 1 IP， DN 4 IP, DN 6 IP }<img src="https://img-blog.csdn.net/20180405231321209?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3Q4OTQ2OTAyMzA=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70#pic_center" alt="在这里插入图片描述"><br>因此，对于 block A，客户端将创建以下步骤来创建管道：</li>
</ol>
<ul>
<li>客户端将选择列表中的第一个 DataNode （DN1）并建立 TCP/IP 连接；</li>
<li>客户端将通知 DN 1 准备好接收该 block，它还会将下两个 DataNode（DN 4, 6）的 IP 地址提供给 DN 1；</li>
<li>DN 1 将连接 DN 4，并通知 DN 4 准备好接受该 block，同时将 DN 6 的 IP 地址告知给 DN 4。然后 DN 4<br>将告诉 DN 6 准备好接受数据；</li>
<li>接下来，准备就绪的确认将遵循相反的顺序，即从 DN 6 -&gt; DB 4 -&gt; DN 1；</li>
<li>最后 DN 1 将通知客户端所有的 DataNode 都以准备就绪，并且将在 DataNode 1，4 和 6 之间形成管道；</li>
<li>现在，管道设置完成，客户端将最终的数据以<strong>流式方式</strong>处理。<h3 id="2-数据流"><a href="#2-数据流" class="headerlink" title="2) 数据流"></a>2) 数据流</h3>由于管道已经创建，客户端会将数据推送到管道中。不过不要忘记，在 HDFS 中，数据是基于复制因子进行复制的，所以，在假设复制因子为 3 时，block A 将存储到 3 个 DataNode 中。移动到最前的，客户端仅仅是将 block A 复制到 DN1。复制总是按照顺序进行的。<img src="https://img-blog.csdn.net/20180405231336949?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3Q4OTQ2OTAyMzA=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70#pic_center"><br>因此，在复制过程中将执行以下的步骤：</li>
<li>一旦该 block 被客户端写入 DN 1，DN 1 将连接到 DN 4；</li>
<li>然后，DN 1 将推送管道中的 block，数据将被复制到 DN 4；</li>
<li>同样的 DN 4 将连接到 DN 6 并将 block 复制为最后一个副本。<h3 id="3-管道关闭与确认阶段"><a href="#3-管道关闭与确认阶段" class="headerlink" title="3) 管道关闭与确认阶段"></a>3) 管道关闭与确认阶段</h3>一旦 block 被复制到所有的 3 个 DataNode 中，就会发生一系列的确认操作，以确保客户端和 NameNode 确信数据已经写入成功。然后客户端将最终关闭管道以结束 TCP 会话。</li>
</ul>
<p>如下图所示，确认以相反的顺序发生，即从 DN 6 到 DN 4，再到 DN 1。最后，DN 1 将把 3 个确认（包括它自己的）推送到流水线中并发送给客户端，客户端将通知 NameNode 数据已经成功写入。<strong>此时，NameNode 将更新元数据，客户端将关闭管道。</strong><img src="https://img-blog.csdn.net/20180405231351917?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3Q4OTQ2OTAyMzA=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70#pic_center" alt="在这里插入图片描述"><br>类似的，block B 也将被复制到与 block B 并行的 DataNode 中，因此，这里需要注意一下几点：</p>
<p>客户端将同时将 block A 和 block B 复制到第一个 DataNode 上；<br>因此，在这个示例下，将为两个 block 形成两条管道，上述所有过程将在这<strong>两条管道中并行发生</strong>；<br>客户端将该 block 写入第一个 DataNode，然后 DataNode 将顺序复制该 block</p>
<p><img src="https://img-blog.csdn.net/20180405231405266?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3Q4OTQ2OTAyMzA=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="在这里插入图片描述"><br>如上图所示，客户端为两个 block 一共创建了两个管道，以下是各个管道中每个 block 正在进行的操作流程：</p>
<ul>
<li>block A 的管道：1A -&gt; 2A -&gt; 3A -&gt; 4A</li>
<li>block B 的管道：1B -&gt; 2B -&gt; 3B -&gt; 4B -&gt; 5B -&gt; 6B</li>
</ul>
<h2 id="数据写入实现"><a href="#数据写入实现" class="headerlink" title="数据写入实现"></a>数据写入实现</h2><p><img src="https://img-blog.csdnimg.cn/20200603212957479.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM2NzA1NzA1,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>写入数据的详细流程：</p>
<ol>
<li>客户端通过在 DistributedFileSystem 上调用 create() 方法来创建文件（步骤1）；</li>
<li>DistributedFileSystem 对 NameNode 进行 RPC 调用，以在文件系统的 namespace 中创建一个新的文件，此时没有与之关联的 block（步骤2）（NameNode 会执行各种检查以确保文件不存在，并且确保客户端具有创建文件的正确权限。只有通过了这些检查，才会创建新文件成功，否则客户端抛出 IOException）</li>
<li>DistributedFileSystem 返回一个 FSDataOutputStream 对象以开始写入数据。与读取数据一样，FSDataOutputStream 封装了一个 DFSOutputStream 对象，它处理与DataNode 和 NameNode 的通信。当客户端开始写入数据（步骤3）时，DFSOutputStream 将其拆分成数据包（packet），写入内部的数据队列，数据队列由 DataStreamer 使用，它通过选择合适的 DataNode 列表来存储副本，从而要求 NameNode 分配新的 block。DataNode列表会形成一个管道（假设副本数为3），其中包含3个节点。</li>
<li>DataStreamer 将数据包以流式传输的方式传输到流水线中的第一个 DataNode，该数据流将数据包存储到第一个 DataNode 中并将其转发到流水线中的第二个 DataNode。类似地，第二个 DataNode 节点会将数据包转发到流水线中的第三个 DataNode 节点（步骤4）；</li>
<li>DFSOutputStream 还维护了一个正在等待的数据包的内部的 ack 队列，由 DataNode 确认。只有在流水线中的书友 DataNode 节点都确认了数据包（步骤5）后才会将数据包从 ack 队列中删除；</li>
<li>如果数据在写入过程中发生故障，那么：(1) 首先关闭管道，并将 ack 队列中的所有数据包添加到数据队列的前端，以便故障节点下游的 DataNode 不会错过任何数据包。(2) 正常状态的 DataNode 上的 block 会被赋予一个新的标识，以便如果失败的 DataNode 稍后恢复后，删除发生故障的 DataNode 上的部分 block。(3) 然后将失败的 DataNode 从流水线中移除，并将该 block 的其余数据写入流水线中的两个良好的 DataNode。(4) 当 NameNode 注意到该 block 被复制不足时，会安排它在另外一个节点上创建另一个副本。<br>如果多个 DataNode 在写入 block 发生故障，那么只要写入 dfs.replication.min 最小副本数，写入操作也会成功，该 block 将异步复制，知道其目标复制因子达到 dfs.replication 指定的数量。</li>
<li>当客户端完成写入数据后，它会在流上调用 close() 方法（步骤6）。</li>
<li>close() 操作会将所有剩余的数据包刷新到 DataNode 管道，并联系 NameNode 以表示文件以传输完成（步骤7），并等待确认。</li>
<li>NameNode 已经知道该文件由哪些 block 组成（因为通过 DataStreamer 分配的 block），所以它只需要等待 block 最小程度（dfs.replication.min）的被复制，便可以返回成功，也是此时，NameNode 才会将文件创建操作提交到 EditLog 中。</li>
</ol>
<h2 id="数据读取原理"><a href="#数据读取原理" class="headerlink" title="数据读取原理"></a>数据读取原理</h2><p><img src="https://img-blog.csdnimg.cn/20200603213040381.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM2NzA1NzA1,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>现在，读取数据将发生以下步骤：</p>
<ul>
<li>客户端将与 NameNode 联系，询问文件”example.txt“的 block 元数据；</li>
<li>NameNode 返回存储的每个块（block A 和 block B）的 DataNode 列表； </li>
<li>然后，客户端将连接到列表中最近的DataNode；</li>
<li>客户端开始从 DataNode 并行读取数据（DN 1 的 block A 和 DN 3 的 block B） </li>
<li>一旦客户端获得了所有必须的block，它就会将这些 block 组合起来形成一个文件。</li>
<li>在提供给客户端读取请求时，HDFS选择最接近客户端的副本，这减少了读取延迟和带宽消耗。因此，如果可能，会选择与阅读节点位于同一个机架上的副本。</li>
</ul>
<h2 id="数据读取实现"><a href="#数据读取实现" class="headerlink" title="数据读取实现"></a>数据读取实现</h2><p><img src="https://img-blog.csdnimg.cn/20200603213210698.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM2NzA1NzA1,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>读取数据的详细流程：</p>
<ol>
<li>客户端通过调用 FileSystem 对象的 open() 方法来打开它希望读取的文件，其实就是创建了一个 DistributedFileSystem 对象（步骤1）；</li>
<li>DistributedFileSystem 使用 RPC 调用 NameNode 来确定文件中前几个 block 的位置，同时对于每个 block，NameNode 返回具有该 block 副本的 DataNode 的地址，此外，DataNode 根据它们与客户端的接近程度进行排序（根据集群网络的拓扑结构），如果客户端本身就是一个 DataNode，那么它将从本地直接读取（步骤2）。</li>
<li>DistributedFileSystem 返回一个 FSDataInputStream（支持文件搜索的输入流）给客户端，供其从中读取数据；</li>
<li>FSDataInputStream 依次包装一个 DFSInputStream，它们用于管理 DataNode 和 NameNode 的 I/O 读写；</li>
<li>客户端调用 stream 上的 read() 方法（步骤3）；</li>
<li>DFSInputStream 中存储了文件中前几个 block 所在 DataNode 的地址，根据这些信息连接到文件中离 block 的最近的DataNode。数据从 DataNode 返回至客户端，客户端在数据流上重复调用 read() 方法（不同 block 并行读取）（步骤4，5）；</li>
<li>当 block 全部传输完成后，DFSInputStream 将关闭与 DataNode 的连接；</li>
<li>当客户端完成数据读取后，调用 FSDataInputStream 上 close() 方法以关闭流（步骤6）；</li>
</ol>
<h3 id="心跳检测、block-状态报告与数据重新复制"><a href="#心跳检测、block-状态报告与数据重新复制" class="headerlink" title="心跳检测、block 状态报告与数据重新复制"></a>心跳检测、block 状态报告与数据重新复制</h3><p>文件以 block 形式写入 DataNode 后，其副本数必须满足系统配置的数量（dfs.replication），即使是在之后 DataNode 发生了故障，比如磁盘错误或者宕机，HDFS 都应该有能力来处理这样的情况。所以这里就涉及到了几个问题：</p>
<ol>
<li>HDFS 如果确定 Datanode 的状态</li>
<li>如何确定哪些 block 出现了丢失</li>
<li>Datanode 发生故障后，如何保障数据的安全</li>
</ol>
<p>在 HDFS 中，Datanode 以及 block 的元信息都通过 Namenode 来管理。Namenode 会周期性地从集群中的每个 Datanode 接收心跳信号和 block 状态报告（Blockreport）。接收到心跳信号意味着该 Datanode 节点工作正常，而 block 状态报告则包含了一个该 Datanode 上所有 block 的列表。</p>
<p>那么根据心跳信号以及 block 状态报告，Namenode 可以知道每一个 Datanode 是否正常工作，以及哪些 block 被损坏了。如果一个 Datanode 宕机了，那么任何存储在它之上的所有 block 将不再有效。Namenode 不断地检测这些 block 是否满足副本系数，一旦发现某个 block 的副本系数低于指定值，就会启动复制操作。可能需要重新复制的操作有：某个 Datanode 节点失效、某个副本遭到破坏、Datanode 上的磁盘错误、或者文件的副本系数变大。</p>
<h2 id="存储空间回收"><a href="#存储空间回收" class="headerlink" title="存储空间回收"></a>存储空间回收</h2><p>文件的删除和恢复<br>当用户或应用程序删除某个文件时，这个文件并<strong>没有</strong>立刻从 HDFS 中删除。实际上 HDFS 会将这个文件<strong>重命名并转移到 /trash 目录</strong>，所以只要该文件在 /trash 目录中，就可以被迅速恢复。文件在 /trash 中保存的时间通过 <strong>fs.trash.interva</strong>l 配置，当超过这个时间时，Namenode 就会将文件从 <strong>namespace</strong> 中删除。删除文件会使得该文件的 block 被释放。</p>
<p>Namenode 在做类似的常规扫描时，<strong>Namenode 找点孤儿 block</strong>（不被任何文件包含的 block）并删除<strong>它们的元数据</strong>。然后 Datanode 在和 Namenode 交互心跳信息中，报告它所拥有的 block 子集的信息，Namenode 回复 Datanode 哪些 block 在元数据中已经不存在了，<strong>Datanode 便可以任意删除这些 block 副本了</strong>。</p>
<p>减少副本系数<br>同样的，当一个文件的副本系数被减小后，Namenode 会选择过剩的副本删除。其原理与上面的类似。</p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/t894690230/article/details/79830271">原文链接</a></p>

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/" rel="tag"><i class="fa fa-tag"></i> 大数据</a>
              <a href="/tags/Hadoop/" rel="tag"><i class="fa fa-tag"></i> Hadoop</a>
              <a href="/tags/hdfs/" rel="tag"><i class="fa fa-tag"></i> hdfs</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2020/06/03/Java%E4%B9%8B%E5%BC%82%E5%B8%B8/" rel="prev" title="Java之异常">
      <i class="fa fa-chevron-left"></i> Java之异常
    </a></div>
      <div class="post-nav-item">
    <a href="/2020/06/04/%E6%AF%8F%E6%97%A5%E4%B8%80%E9%A2%98-10%E6%8B%AC%E5%8F%B7%E7%94%9F%E6%88%90/" rel="next" title="每日一题@10括号生成">
      每日一题@10括号生成 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#HDFS"><span class="nav-number">1.</span> <span class="nav-text">HDFS</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%9E%B6%E6%9E%84%E4%B8%8E%E5%8E%9F%E7%90%86"><span class="nav-number">2.</span> <span class="nav-text">架构与原理</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#NameNode-amp-DataNode"><span class="nav-number">3.</span> <span class="nav-text">NameNode &amp; DataNode</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E5%9D%97%EF%BC%88Block%EF%BC%89"><span class="nav-number">4.</span> <span class="nav-text">数据块（Block）</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%85%83%E6%95%B0%E6%8D%AE"><span class="nav-number">5.</span> <span class="nav-text">元数据</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E5%86%99%E5%85%A5%E5%8E%9F%E7%90%86"><span class="nav-number">6.</span> <span class="nav-text">数据写入原理</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-%E7%AE%A1%E9%81%93%E8%AE%BE%E7%BD%AE"><span class="nav-number">6.1.</span> <span class="nav-text">1) 管道设置</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-%E6%95%B0%E6%8D%AE%E6%B5%81"><span class="nav-number">6.2.</span> <span class="nav-text">2) 数据流</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-%E7%AE%A1%E9%81%93%E5%85%B3%E9%97%AD%E4%B8%8E%E7%A1%AE%E8%AE%A4%E9%98%B6%E6%AE%B5"><span class="nav-number">6.3.</span> <span class="nav-text">3) 管道关闭与确认阶段</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E5%86%99%E5%85%A5%E5%AE%9E%E7%8E%B0"><span class="nav-number">7.</span> <span class="nav-text">数据写入实现</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E8%AF%BB%E5%8F%96%E5%8E%9F%E7%90%86"><span class="nav-number">8.</span> <span class="nav-text">数据读取原理</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E8%AF%BB%E5%8F%96%E5%AE%9E%E7%8E%B0"><span class="nav-number">9.</span> <span class="nav-text">数据读取实现</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%BF%83%E8%B7%B3%E6%A3%80%E6%B5%8B%E3%80%81block-%E7%8A%B6%E6%80%81%E6%8A%A5%E5%91%8A%E4%B8%8E%E6%95%B0%E6%8D%AE%E9%87%8D%E6%96%B0%E5%A4%8D%E5%88%B6"><span class="nav-number">9.1.</span> <span class="nav-text">心跳检测、block 状态报告与数据重新复制</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%AD%98%E5%82%A8%E7%A9%BA%E9%97%B4%E5%9B%9E%E6%94%B6"><span class="nav-number">10.</span> <span class="nav-text">存储空间回收</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="imarktsh"
      src="https://img-blog.csdnimg.cn/2020053010414625.jpg">
  <p class="site-author-name" itemprop="name">imarktsh</p>
  <div class="site-description" itemprop="description">明天一定学</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">149</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">3</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">24</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>



      </div>
        <div class="back-to-top motion-element">
          <i class="fa fa-arrow-up"></i>
          <span>0%</span>
        </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">imarktsh</span>
</div>

    <!-- 网站运行时间的设置 -->
    <span id="timeDate">载入天数...</span>
    <span id="times">载入时分秒...</span>  | It is building your life.
    <script>
        var now = new Date();
        function createtime() {
            var grt= new Date("01/05/2020 00:00:00");//此处修改你的建站时间或者网站上线时间
            now.setTime(now.getTime()+250);
            days = (now - grt ) / 1000 / 60 / 60 / 24; dnum = Math.floor(days);
            hours = (now - grt ) / 1000 / 60 / 60 - (24 * dnum); hnum = Math.floor(hours);
            if(String(hnum).length ==1 ){hnum = "0" + hnum;} minutes = (now - grt ) / 1000 /60 - (24 * 60 * dnum) - (60 * hnum);
            mnum = Math.floor(minutes); if(String(mnum).length ==1 ){mnum = "0" + mnum;}
            seconds = (now - grt ) / 1000 - (24 * 60 * 60 * dnum) - (60 * 60 * hnum) - (60 * mnum);
            snum = Math.round(seconds); if(String(snum).length ==1 ){snum = "0" + snum;}
            document.getElementById("timeDate").innerHTML = "已运行 "+dnum+" 天 ";
            document.getElementById("times").innerHTML = hnum + " 小时 " + mnum + " 分 " + snum + " 秒";
    }
    setInterval("createtime()",250);
    </script>

        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>

<script src="/js/utils.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>

<script src="/js/bookmark.js"></script>




  















  

  

</body>
</html>
