<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/128128.ico">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/3232.ico">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/1616.ico">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="https://fonts.loli.net/css?family=Noto Serif SC:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">
<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"onlyear.com","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":true,"show_result":true,"style":null},"back2top":{"enable":true,"sidebar":true,"scrollpercent":true},"bookmark":{"enable":true,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="这次安装Hadoop3.2 + spark3.0.1 碰到一些问题">
<meta property="og:type" content="article">
<meta property="og:title" content="Hadoop3.2安装">
<meta property="og:url" content="http://onlyear.com/2020/11/03/Hadoop3-2%E5%AE%89%E8%A3%85/index.html">
<meta property="og:site_name" content="imarktsh的博客">
<meta property="og:description" content="这次安装Hadoop3.2 + spark3.0.1 碰到一些问题">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://img-blog.csdnimg.cn/20201028133036523.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM2NzA1NzA1,size_16,color_FFFFFF,t_70#pic_center">
<meta property="og:image" content="https://img-blog.csdnimg.cn/2020102813341698.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM2NzA1NzA1,size_16,color_FFFFFF,t_70#pic_center">
<meta property="article:published_time" content="2020-11-03T11:18:00.000Z">
<meta property="article:modified_time" content="2020-11-03T11:19:44.000Z">
<meta property="article:author" content="imarktsh">
<meta property="article:tag" content="大数据">
<meta property="article:tag" content="Hadoop">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://img-blog.csdnimg.cn/20201028133036523.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM2NzA1NzA1,size_16,color_FFFFFF,t_70#pic_center">

<link rel="canonical" href="http://onlyear.com/2020/11/03/Hadoop3-2%E5%AE%89%E8%A3%85/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>Hadoop3.2安装 | imarktsh的博客</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">imarktsh的博客</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">多沉淀 多复盘</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="reading-progress-bar"></div>
  <a role="button" class="book-mark-link book-mark-link-fixed"></a>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://onlyear.com/2020/11/03/Hadoop3-2%E5%AE%89%E8%A3%85/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="https://img-blog.csdnimg.cn/2020053010414625.jpg">
      <meta itemprop="name" content="imarktsh">
      <meta itemprop="description" content="明天一定学">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="imarktsh的博客">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Hadoop3.2安装
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2020-11-03 19:18:00 / 修改时间：19:19:44" itemprop="dateCreated datePublished" datetime="2020-11-03T19:18:00+08:00">2020-11-03</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/" itemprop="url" rel="index"><span itemprop="name">大数据</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv" style="display: none;">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span id="busuanzi_value_page_pv"></span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>这次安装Hadoop3.2 + spark3.0.1 碰到一些问题</p>
<span id="more"></span>
<p>现在百度上的博客质量真的不行，看了几篇博客搭建Hadoop一直报错 查询错误也是你抄我的 我抄你的 没有什么有价值的东西<br> 重装两次都没成功 昨天头疼都睡不着<br> 今天再b站找到一个视频按照安装文档成功装上 主要是Hadoop3比2的版本多了权限管理，需要设置用户要不然就会报错集群不能启动<br> 说一下昨天的错误吧<br> <img src="https://img-blog.csdnimg.cn/20201028133036523.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM2NzA1NzA1,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<p>说的很明显就是权限问题，为啥我在启动脚本加入了root用户还是启动不了<br>可能是某个脚本没有改好导致集群不能启动<br>这个安装文档把需要的用户创建好了加入到root组里面就可以正常启动<br><img src="https://img-blog.csdnimg.cn/2020102813341698.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM2NzA1NzA1,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<p> 安装文档贴出来：完全可用</p>
<pre><code class="python">本文档推荐用word打开（wps也可以，就是各级目录不好展开合上），另外zookeeper和spark的IEDA部署和API编程后续也会尽快录制视频上传。
                    ——compiled by：郑慧乐

参考pdf：《大数据技术基础系统部署指南v3》（更详细，可对照结果截图，但有部分歧义）

b站配套视频：
①Virtualbox&amp;Centos7 hadoop-3.2.1三台主机伪分布式、完全分布式配置安装教程：https://www.bilibili.com/video/BV1kE411c7KG/
②Virtualbox&amp;Centos7  三台主机zookeeper集群和spark集群配置安装教程：
https://www.bilibili.com/video/BV1k7411y7SD/

1.    Hadoop
注：1.1~1.3无特殊说明三台服务器（zhl-1~zhl-3）在xshell6上一起操作运行；1.4~1.5无特殊说明xshell6先只在一台服务器（zhl-1）上运行，后通过scp同步到其它服务器（zhl-2、zhl-3上）；以下所有步骤后加★意为下面代码可能需要具体修改（加红部分），没检查确认前不要看都不看直接完全copy代码段

1.1安装OpenJDK1.8
1.安装 jdk1.8
yum install java-1.8.0-openjdk-devel -y

2. whereis 命令查找 java 安装的真实所在位置，设置jdk环境变量
whereis java
这里我的路径：
/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.242.b08-0.el7_7.x86_64
3.下载vim
yum install vim -y
vim可以完全替代vi，用于编辑vim直观好处是代码是彩色的，vi只是一片白色

4.★将步骤2中找到具体路径添加到系统环境变量中
vim /etc/profile
export JAVA_HOME=/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.242.b08-0.el7_7.x86_64
export JRE_HOME=$&#123;JAVA_HOME&#125;/jre
export CLASSPATH=.:$&#123;JAVA_HOME&#125;/lib/dt.jar:$&#123;JAVA_HOME&#125;/lib/tools.jar:$&#123;JRE_HOME&#125;/lib/rt.jar
export HADOOP_HOME=/usr/local/hadoop-3.2.1
export PATH=$&#123;PATH&#125;:$&#123;JAVA_HOME&#125;/bin:$&#123;HADOOP_HOME&#125;/bin
source /etc/profile
第1段代码vim进入文本进行编辑
第2段代码输入前按i，进入可编辑模式（下面会有INSERT显示）；代码输入完后按键盘左上角esc键，退出可编辑模式，然后输入:wq!保存强制退出，后面所有vim均是如此（如果只是输入:q，则会不保存退出）
第3段上面的source /etc/profile指令使得jdk环境生效
后面黑色加深意思为三台都先加上，后面完全分布式hadoop会有用。
5.查看jdk环境是否添加成功
java -version

1.2建立Hadoop用户
1. groupadd 命令建立新用户组
groupadd hadoop 
groupadd hdfs 
groupadd hbase 
groupadd hive
groupadd spark 

2. 将组名（如hadoop）添加到用户组（如root）中
usermod -a -G hadoop root
usermod -a -G hdfs root
usermod -a -G hbase root
usermod -a -G hive root
usermod -a -G spark root
cat /etc/group
其中cat /etc/group是查询是否添加成功（也可不执行）
1.3设置集群环境
1. ★将集群的各台主机添加到各台主机的 hosts 列表中
vim /etc/hosts
192.168.1.11 zhl-1
192.168.1.12 zhl-2
192.168.1.13 zhl-3

2.重启服务器，检查network服务是否生效
reboot
此时会发现xshell6断开连接（变红），等虚拟机重新加载显示出login登录界面，再在xshell6处重新连接即可（变绿）。

3. ★用ping检查各虚拟机是否互联
ping zhl-1
ping zhl-2
ping zhl-3
ping下发现正常就直接用ctrl+Z中止进程

4.关闭服务器防火墙
systemctl status firewalld.service
systemctl disable firewalld.service
systemctl stop firewalld.service
systemctl status firewalld.service
第1段代码块：查看当前系统中的防火墙服务的状态，查看是否关闭
若systemctl status firewalld.service显示为inactive状态，后三段代码块可以忽略不执行
第2段代码块：取消开机启动防火墙，确保重启后防火墙为关闭状态
第3段代码块：关闭当前系统中的防火墙服务
第4段代码块：查看当前系统中的防火墙服务的状态，查看是否关闭

5. 设置 selinux 将 SELINUX 改为 disabled
vim /etc/selinux/config
SELINUX=enforcing改成SELINUX= disabled

6. ★配置SSH无密钥登陆
ssh-keygen -t rsa
ssh-copy-id zhl-1
ssh-copy-id zhl-2
ssh-copy-id zhl-3
每执行完一次ssh-copy-id zhl-1，输入yes，接着再输入密码，然后再执行ssh-copy-id zhl-2，同理再执行ssh-copy-id zhl-3

7. ★检查无密钥登录配置成功
ssh zhl-1
exit
ssh zhl-2
exit
ssh zhl-3
exit

1.4安装Hadoop
从这里开始只操作zhl-1一台,无特殊说明zhl-2、zhl-3暂不操作，等zhl-1配置完后后期需要时候会通过scp同步到另外两台服务器上
1. 安装wget指令
yum install wget -y
wget 是一个从网络上自动下载文件的自由工具

2. 下载 hadoop 软件包
wget https://mirrors.tuna.tsinghua.edu.cn/apache/hadoop/common/stable/hadoop-3.2.1.tar.gz

3. 将 hadoop 安装包放入/usr/local 中并解压
chown -R root /usr/local
tar zxvf hadoop-3.2.1.tar.gz -C /usr/local
cd /usr/local
ll

4.检查安装成功
cd /usr/local/hadoop-3.2.1
bin/hadoop version
这里直接cd或者cd ~可以返回到底，cd ..可以返回上一个文件目录，ls是仅列出当前目录下的所有文件名，ll则是详细列出，运行不了就cd /usr/local/hadoop-3.2.1到这个目录下，就能运行了，后面很多都是要cd xxx(具体目录)下操作的
1.5运行hadoop
无特殊说明只操作zhl-1，而zhl-2、zhl-3暂不操作
Hadoop安装分为3种：
①单机模式:单机模式: Hadoop默认模式为非分布式模式(本地模式) ，无需进行其他配置即可运行。非分布式即单Java进程，方便进行调试。
②伪分布式模式: Hadoop可以在单节点上以伪分布式的方式运行，Hadoop 进程以分离的Java进程来运行，节点既作为NameNode也作为DataNode,同时，读取的是HDFS中的文件。
③完全分布式模式:使用多个节点构成集群环境来运行Hadoop。
实际使用的话是完全分布式，因此不是出于初学目的的话下面可以略过1.5.1和1.5.2有关本地模式和伪分布式的操作，省时间直接进行1.5.3完全分布式最终完成hadoop的3台集群工作任务
1.5.1    本地运行hadoop（单机模式） 
1. 运行 hadoop 例子的 jar 包，查看有哪些例程。
cd /usr/local/hadoop-3.2.1
bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.1.jar

2. 在本地模式下运行grep例程
mkdir input
bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.1.jar grep input output &#39;per[a-z.]+&#39;
上述mkdir input的意为新建一个名叫input的目录

3. 查看输出 output 目录中的结果
cd output
ls
cat part-r-00000

1.5.2    伪分布式hadoop 
进行伪分布式hadoop前在这里可以考虑给zhl-1、zhl-2、zhl-3系统三个都各自备份；
操作完伪分布式后可以给zhl-1再次备份然后zhl-1回档到第一次备份（可以两次都不备份不回档直接做），zhl-2、zhl-3不用操作
理由：后面的1.5.3完全分布式hadoop修改的文件跟伪分布式有重叠，只是内容不一样，当然直接再改也行；另外养成系统备份的好习惯，出了问题好回档，不用全部重做一遍
1.5.2.1伪分布式运行HDFS
1. 配置core-site.xml
vim /usr/local/hadoop-3.2.1/etc/hadoop/core-site.xml
  &lt;property&gt; 
    &lt;name&gt;fs.defaultFS&lt;/name&gt; 
    &lt;value&gt;hdfs://localhost:9000&lt;/value&gt; 
    &lt;final&gt;true&lt;/final&gt; 
  &lt;/property&gt;
第二段代码块在&lt;configuration&gt;和&lt;/configuration&gt;之间添加！！（下面带&lt;property&gt;和&lt;/property&gt;的均如此）
上面localhost就可以了，不用改成zhl-1

2. 配置hdfs-site.xml 
vim /usr/local/hadoop-3.2.1/etc/hadoop/hdfs-site.xml
  &lt;property&gt; 
    &lt;name&gt;dfs.replication&lt;/name&gt; 
    &lt;value&gt;1&lt;/value&gt; 
  &lt;/property&gt;
输入了vim后如果跳出[O]pen Read-Only, (E)dit anyway, (R)ecover, (Q)uit, (A)bort的界面，按键盘E编辑就行了

3.初始化名称节点
cd /usr/local/hadoop-3.2.1
bin/hdfs namenode -format

4.★ 给当前用户配置为 root,随后开启hdfs服务守护进程
export HDFS_NAMENODE_USER=root
export HDFS_DATANODE_USER=root
export HDFS_SECONDARYNAMENODE_USER=root
vim /usr/local/hadoop-3.2.1/etc/hadoop/hadoop-env.sh
export JAVA_HOME=/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.242.b08-0.el7_7.x86_64
sbin/start-dfs.sh

5. jps查看JVM 中的hadoop进程
jps

6. 伪分布式模式运行wordcount例程：先上传文本文件到 hdfs 上的相应的文件目录下
bin/hdfs dfs -mkdir /user
bin/hdfs dfs -mkdir /user/root
bin/hdfs dfs -mkdir input
bin/hdfs dfs -put etc/hadoop/*.xml input
下面一直ls的步骤可跳过
ls
bin/hdfs dfs -ls 
bin/hdfs dfs -ls /user
bin/hdfs dfs -ls /user/root
bin/hdfs dfs -ls /user/root/input

7. 运行grep例程
bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.1.jar grep input output &#39;dfs[a-z.]+&#39;
查找当前用户在 hdfs 文件系统中默认目录下的 input 目录中的文本文件中包含有 dfs 的单词，并输出至默认目录/user/root下的 output 目录中

8.运行成功后查看 output 目录中的结果
bin/hdfs dfs -ls /user/root/output
bin/hdfs dfs -cat output/*
下面也可以将结果传回到本地文件系统（可跳过）
bin/hdfs dfs -get output output
ls
ls output/*
cat output/*

9.关闭伪分布式 HDFS
sbin/stop-dfs.sh
jps

1.5.2.2伪分布式运行YARN
1. 配置mapred-site.xml
vim etc/hadoop/mapred-site.xml
  &lt;property&gt; 
    &lt;name&gt;mapreduce.framework.name&lt;/name&gt; 
    &lt;value&gt;yarn&lt;/value&gt;
  &lt;/property&gt; 
  &lt;property&gt; 
    &lt;name&gt;mapreduce.application.classpath&lt;/name&gt; 
    &lt;value&gt;$HADOOP_MAPRED_HOME/share/hadoop/mapreduce/*:$HADOOP_MAPRED_HOME/share/hadoop/mapreduce/lib/*&lt;/value&gt;
  &lt;/property&gt;

2.配置yarn-site.xml
vim etc/hadoop/yarn-site.xml
  &lt;property&gt; 
    &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt; 
    &lt;value&gt;mapreduce_shuffle&lt;/value&gt; 
  &lt;/property&gt; 
  &lt;property&gt; 
    &lt;name&gt;yarn.nodemanager.env-whitelist&lt;/name&gt; 
    &lt;value&gt;JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_MAPRED_HOME&lt;/value&gt; 
  &lt;/property&gt;

3.启动 YARN 服务守护进程
export YARN_RESOURCEMANAGER_USER=root
export YARN_NODEMANAGER_USER=root
sbin/start-yarn.sh

4.关闭伪分布式YARN
jps 
sbin/stop-yarn.sh
jps

1.5.3    完全分布式hadoop 
（做过1.5.2伪分布式的无视这里）：如果跳过了1.52伪分布式，则在这里系统备份zhl-1、zhl-2、zhl-3（养成系统备份的好习惯，出了问题好回档，不用全部重做一遍）

下面依旧是只操作zhl-1，无特殊提示zhl-2、zhl-3不操作

1.★ 配置hadoop-env.sh运行环境
vim /usr/local/hadoop-3.2.1/etc/hadoop/hadoop-env.sh
export JAVA_HOME=/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.242.b08-0.el7_7.x86_64
export HDFS_NAMENODE_USER=root
export HDFS_DATANODE_USER=root
export HDFS_SECONDARYNAMENODE_USER=root

2.★配置core-site.xml(下面&lt;value&gt;hdfs://zhl-1:9000&lt;/value&gt;改成自己的)
vim /usr/local/hadoop-3.2.1/etc/hadoop/core-site.xml
  &lt;property&gt;
    &lt;!-- 必须设置：默认文件系统（存储层和运算层解耦 --&gt; 
    &lt;!-- 此处值为uri结构：使用内置的hdfs系统 端口号一般都是9000 --&gt;
    &lt;name&gt;fs.defaultFS&lt;/name&gt; 
    &lt;value&gt;hdfs://zhl-1:9000&lt;/value&gt; 
    &lt;final&gt;true&lt;/final&gt; 
  &lt;/property&gt;
  &lt;property&gt; 
    &lt;!-- 必须设置：hadoop在本地的工作目录，用于放hadoop进程的临时数据，可以自己指定 --&gt;
    &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; 
    &lt;value&gt;/root/hadoop/tmp&lt;/value&gt; 
  &lt;/property&gt;
&lt;property&gt;和&lt;/property&gt;均在&lt;configuration&gt;&lt;/configuration&gt;之间添加！！

3.★配置hdfs-site.xml（下面&lt;value&gt;zhl-1:9870&lt;/value&gt;改成自己的）
vim /usr/local/hadoop-3.2.1/etc/hadoop/hdfs-site.xml
  &lt;property&gt;
    &lt;!-- hdfs保存namenode当前数据的路径，默认值需要配环境变量，建议使用自己创建的路径, 方便管理--&gt;
    &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt; 
    &lt;value&gt;/root/hadoop/dfs/name&lt;/value&gt; 
    &lt;final&gt;true&lt;/final&gt; 
  &lt;/property&gt; 
  &lt;property&gt; 
    &lt;!-- hdfs保存datanode当前数据的路径，默认值需要配环境变量，建议使用自己创建的路径, 方便管理--&gt;
    &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt; 
    &lt;value&gt;/root/hadoop/dfs/data&lt;/value&gt;
    &lt;final&gt;true&lt;/final&gt; 
  &lt;/property&gt; 
  &lt;property&gt; 
    &lt;!-- hdfs存储数据的副本数量（避免一台宕机），可以不设置，默认值是3--&gt; 
    &lt;name&gt;dfs.replication&lt;/name&gt; 
    &lt;value&gt;3&lt;/value&gt; 
  &lt;/property&gt; 
  &lt;property&gt;
   &lt;!-- hdfs监听namenode的web的地址，默认就是9870端口，如果不改端口也可以不设置--&gt; 
    &lt;name&gt;dfs.namenode.http-address&lt;/name&gt; 
    &lt;value&gt;zhl-1:9870&lt;/value&gt;
  &lt;/property&gt;
  &lt;property&gt;
    &lt;!-- 配置为false后，可以允许不要检查权限就生成dfs上的文件，方便倒是方便了，但是你需要防止误删除 --&gt;
    &lt;name&gt;dfs.permissions&lt;/name&gt;
    &lt;value&gt;false&lt;/value&gt;
  &lt;/property&gt;
  &lt;property&gt;
    &lt;name&gt;dfs.webhdfs.enabled&lt;/name&gt;
    &lt;value&gt;true&lt;/value&gt;
  &lt;/property&gt;

4.★配置mapred-site.xml（修改2处：&lt;value&gt;zhl-1:10020&lt;/value&gt;和&lt;value&gt;zhl-1:19888&lt;/value&gt;改成自己的）
vim /usr/local/hadoop-3.2.1/etc/hadoop/mapred-site.xml
  &lt;property&gt; 
  &lt;!-- 必须设置，mapreduce程序使用的资源调度平台，默认值是local,若不改就只能单机运行，不会到集群上了 --&gt;
    &lt;name&gt;mapreduce.framework.name&lt;/name&gt; 
    &lt;value&gt;yarn&lt;/value&gt; 
  &lt;/property&gt;
  &lt;property&gt; 
  &lt;!-- 这是3.2以上版本需要增加配置的，不配置运行mapreduce任务可能会有问题，记得使用自己的路径 --&gt; 
    &lt;name&gt;mapreduce.application.classpath&lt;/name&gt; 
    &lt;value&gt;$HADOOP_MAPRED_HOME/share/hadoop/mapreduce/*:$HADOOP_MAPRED_HOME/share/hadoop/mapreduce/lib/*&lt;/value&gt;
  &lt;/property&gt;
  &lt;property&gt;
    &lt;name&gt;mapreduce.jobhistory.address&lt;/name&gt; 
    &lt;value&gt;zhl-1:10020&lt;/value&gt; 
  &lt;/property&gt;
  &lt;property&gt; 
    &lt;name&gt;mapreduce.jobhistory.webapp.address&lt;/name&gt;
    &lt;value&gt;zhl-1:19888&lt;/value&gt; 
  &lt;/property&gt;

5.★配置yarn-site.xml（&lt;value&gt;zhl-1&lt;/value&gt;改成自己的）
vim /usr/local/hadoop-3.2.1/etc/hadoop/yarn-site.xml
  &lt;property&gt;
    &lt;!-- 必须配置指定YARN的老大(ResourceManager)在哪一台主机 --&gt;
    &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;
    &lt;value&gt;zhl-1&lt;/value&gt;
  &lt;/property&gt;
  &lt;property&gt;
    &lt;!-- 必须配置提供mapreduce程序获取数据的方式默认为空 --&gt;
    &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;
    &lt;value&gt;mapreduce_shuffle&lt;/value&gt;
  &lt;/property&gt;
  &lt;property&gt;
    &lt;name&gt;yarn.nodemanager.env-whitelist&lt;/name&gt;
    &lt;value&gt;JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_MAPRED_HOME&lt;/value&gt;
  &lt;/property&gt;
  &lt;property&gt;
    &lt;!--忽略虚拟内存的检查，如果你是安装在虚拟机上，这个配置很有用，配上去之后后续操作不容易出问题。 --&gt;
    &lt;name&gt;yarn.nodemanager.vmem-check-enabled&lt;/name&gt;
    &lt;value&gt;false&lt;/value&gt;
  &lt;/property&gt;

6.★修改 workers,将localhost删除，zhl-1、zhl-2、zhl-3添加进去
vim /usr/local/hadoop-3.2.1/etc/hadoop/workers
zhl-1
zhl-2
zhl-3
cat查看添加是否成功（可跳过）
cat /usr/local/hadoop-3.2.1/etc/hadoop/workers

7. 配置 hadoop 中/sbin 中的各项文件
①修改start-dfs.sh
vim /usr/local/hadoop-3.2.1/sbin/start-dfs.sh
HDFS_DATANODE_USER=root
HDFS_DATANODE_SECURE_USER=hdfs
HDFS_NAMENODE_USER=root
HDFS_SECONDARYNAMENODE_USER=root

②修改stop-dfs.sh
vim /usr/local/hadoop-3.2.1/sbin/stop-dfs.sh
HDFS_DATANODE_USER=root
HDFS_DATANODE_SECURE_USER=hdfs
HDFS_NAMENODE_USER=root
HDFS_SECONDARYNAMENODE_USER=root

③修改start-yarn.sh
vim /usr/local/hadoop-3.2.1/sbin/start-yarn.sh
YARN_RESOURCEMANAGER_USER=root
HADOOP_SECURE_DN_USER=yarn
YARN_NODEMANAGER_USER=root

④修改stop-yarn.sh
vim /usr/local/hadoop-3.2.1/sbin/stop-yarn.sh
YARN_RESOURCEMANAGER_USER=root
HADOOP_SECURE_DN_USER=yarn
YARN_NODEMANAGER_USER=root

⑤★scp复制 hadoop-3.2.1 到zhl-2、zhl-3上（这里就解释了为什么一直以来只操作zhl-1，而zhl-2和zhl-3不用操作，因为一台配置好了同步到其它台就ok了）
for A in &#123;2..3&#125;; do scp -r /usr/local/hadoop-3.2.1 zhl-$A:/usr/local;done
注意上面代码2、3和zhl-，根据自己情况具体修改，因为现在只在操作zhl-1，所以要scp复制同步到zhl-2、zhl-3上

8.启动集群
①初始化集群的名称节点（format只执行一次，别重复执行！）
/usr/local/hadoop-3.2.1/bin/hdfs namenode -format
（正常情况不执行）如果不小心多次format出问题了，执行下面六步：
cd /usr/local/hadoop-3.2.1
sbin/stop-all.sh
rm -rf /root/hadoop/dfs/name
rm -rf /root/hadoop/dfs/data
rm -rf hadoop.tmp.dir
/usr/local/hadoop-3.2.1/bin/hdfs namenode -format
sbin/start-all.sh

②启动 hadoop 集群
cd /usr/local/hadoop-3.2.1
sbin/start-all.sh
如果warning说logs does not exist.无视掉就好，logs日志可以没有的
一旦使用了sbin/start-all.sh后要切记：任何时候关闭虚拟机前先sbin/stop-all.sh，否则下次可能报错，集群失败，又要重新格式化啥的很麻烦

9.检查集群情况
①在zhl-1、zhl-2、zhl-3中同时输入
jps
查看每台服务器上JVM 中 hadoop 进程运行情况，了解hadoop各组件在服务器集群中的分布情况
   
②★在浏览器中输入
http://192.168.1.11:9870/

点击顶部“Datanodes”下翻找到：
 
监控datanode 的状态（出现了3个绿√代表hadoop集群已经配置成功）

③★在浏览器中输入
http://192.168.1.11:8088/

能看到集群管理页面
 配置是成功的

④只操作zhl-1，关闭 hadoop 集群（该步骤非常重要，start后关机前一定要先stop集群！！）
cd /usr/local/hadoop-3.2.1
sbin/stop-all.sh

这里就3台hadoop完全式分布集群安装就已经成功了，下面的都是用这个集群去运行例程，可以跳过不做，这里总结下：上面在操作的时候，一直在zhl-1上操作，最后scp同步到zhl-2、zhl-3时这么多的配置文件里的zhl-1要改成zhl-2或zhl-3吗？答案是不用的，其他的里面都会是zhl-1，这才是正常的。原先一直用3台xshell6一起操作，导致后面一直被坑出问题，其实只用操作一台，注意避坑。

10.例程1（省时间可不做跳过，建议做一下）：完全分布式运行wordcount
①在此之前先调整时间，避免后面报错
时间同步调整博客：https://blog.csdn.net/selectdb/article/details/81735104
yum install ntp -y
systemctl enable ntpd.service
vim /etc/sysconfig/ntpd
上面的vim添加-g -x参数
systemctl restart ntpd.service
ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime
date

②上传文本文件到 HDFS 中
cd
/usr/local/hadoop-3.2.1/sbin/start-all.sh 
hdfs dfs -mkdir /test
hdfs dfs -put /etc/profile /test/input
hdfs dfs -ls /test/input
hdfs dfs -ls /test/input用于查看(非必要步骤可跳)
mkdir用于新建
/etc/profile是随意选的一个文件
/test和/test/input是自己可以随意起的文件名
注意上面第三步又开启了集群，后面不用时要关掉
（正常情况下不用执行）如果前面有过多次format的行为，第四步会报错，要先离开安全模式，再执行/usr/local/hadoop-3.2.1/bin/hdfs dfs -put test1 /tmp
hadoop dfsadmin -safemode leave

★接下来再次进入：
http://192.168.1.11:9870/

然后点击右上角UtilitiesBrowse the file system
 
③运行 wordcount 例程
hadoop jar $HADOOP_HOME/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.1.jar wordcount /test/input /test/output

★接下来再次进入：
http://192.168.1.11:8088/

 
看到多出了这个，wordcount例程到此完美结束

10.★例程2（省时间可不做跳过，建议做一下）：完全分布式运行蒙特卡洛方法计算圆周率
hadoop jar $HADOOP_HOME/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.1.jar pi 10 1000
 
最后Π结果得出3.1408，想要更精确可以把数字调高，就是运行会变慢
运行时会发现有 
这里的map和reduce有进度条原因是这样的：hadoop的分布式计算框架分为两个阶段，第一个是map阶段，第二个是reduce阶段。map阶段负责对输入文件进行切分处理，然后汇总再分组给reduce进行处理，以达到高效的分布式计算效率

★同样进入：
http://192.168.1.11:8088/

 
看到多出了这个，蒙特卡洛方法计算圆周率例程到此完美结束
至此，hadoop全部配置、例程结束，别忘了输入:    :
/usr/local/hadoop-3.2.1/sbin/stop-all.sh

2.    Zookeeper 
注：无特殊说明只操作zhl-1，而zhl-2、zhl-3不操作。
以下所有步骤后加★意为下面代码可能需要具体修改（加红部分），没检查确认前不要看都不看直接完全copy代码段

2.1 Zookeeper部署
1. 从 zookeeper 官网下载最新版本的安装包。http://zookeeper.apache.org/
cd
wget http://mirror.bit.edu.cn/apache/zookeeper/stable/apache-zookeeper-3.5.7-bin.tar.gz

2. 解压安装 zookeeper，随后查看
tar zxvf apache-zookeeper-3.5.7-bin.tar.gz -C /usr/local/
ls /usr/local/

3. 修改配置文件 zoo.cfg
ls /usr/local/apache-zookeeper-3.5.7-bin/conf/
cp /usr/local/apache-zookeeper-3.5.7-bin/conf/zoo_sample.cfg /usr/local/apache-zookeeper-3.5.7-bin/conf/zoo.cfg
ls /usr/local/apache-zookeeper-3.5.7-bin/conf/
vim /usr/local/apache-zookeeper-3.5.7-bin/conf/zoo.cfg
dataDir=/usr/local/apache-zookeeper-3.5.7-bin/zkData
第二段代码：cp zoo_sample.cfg zoo.cfg将zoo_sample.cfg复制到同目录下，并将名称改为zoo.cfg
最后vim是将原有的dataDir替换掉

4.新建集群数据目录
mkdir /usr/local/apache-zookeeper-3.5.7-bin/zkData
ls /usr/local/apache-zookeeper-3.5.7-bin/

5.启动Zookeeper服务进程
ll /usr/local/apache-zookeeper-3.5.7-bin/bin
/usr/local/apache-zookeeper-3.5.7-bin/bin/zkServer.sh start
jps

6.查看Zookeeper服务状态
/usr/local/apache-zookeeper-3.5.7-bin/bin/zkServer.sh status

7.启动 Zookeeper 客户端连接服务
/usr/local/apache-zookeeper-3.5.7-bin/bin/zkCli.sh

8.查看Zookeeper的目录
ls /

9. 退出Zookeeper客户端
quit

10.退出Zookeeper服务
/usr/local/apache-zookeeper-3.5.7-bin/bin/zkServer.sh stop
jps

11. 修改集群配置文件
在 zookeeper 的数据目录 zkData 中创建 myid 文件：
touch /usr/local/apache-zookeeper-3.5.7-bin/zkData/myid
touch 命令主要用于创建普通文件，如果文件存在，表示修改当前文件时间

★然后修改 zoo.cfg 配置文件(第一行加入即可)：
vim /usr/local/apache-zookeeper-3.5.7-bin/conf/zoo.cfg
#cluster configuration
server.1=zhl-1:2888:3888
server.2=zhl-2:2888:3888
server.3=zhl-3:2888:3888
这里有一个天坑！注意zhl-1:2888:3888和zhl-2:2888:3888和zhl-3:2888:3888最后一个8后面不要留空格，不要留空格，不要留空格，服务端口号后留了空格非常难检查出来，后面会直接导致zookeeper在解析端口号的时候出现异常，从而使：
这里13. 分别在各个服务器上启动 Zookeeper 服务 
出现FAILED而不是STARTED  启动失败！

12. ★分布式部署 Zookeeper(3台)
将zhl-1配置好的软件包复制到zhl-2、zhl-3上（只操作zhl-1）
for i in &#123;2..3&#125;;do scp -r /usr/local/apache-zookeeper-3.5.7-bin zhl-$i:/usr/local;done
可以在zhl-2、zhl-3中输入：
ls /usr/local
查看到：apache-zookeeper-3.5.7-bin 则复制成功

★在下一步开启zookeeper前请务必注意！
仅操作zhl-1：
vim /usr/local/apache-zookeeper-3.5.7-bin/zkData/myid
1

仅操作zhl-2：
vim /usr/local/apache-zookeeper-3.5.7-bin/zkData/myid
2

仅操作zhl-3：
vim /usr/local/apache-zookeeper-3.5.7-bin/zkData/myid
3

13.分别在各个服务器上启动 Zookeeper 服务（若启动失败回看11. ★修改集群配置文件 后面警告）
（jps如果显示有了QuorumPeerMain就不执行）zhl-1、zhl-2、zhl-3一起操作：
/usr/local/apache-zookeeper-3.5.7-bin/bin/zkServer.sh start

14.查看各个服务状态
zhl-1、zhl-2、zhl-3一起操作：
/usr/local/apache-zookeeper-3.5.7-bin/bin/zkServer.sh status

15. 测试故障重新选举 Leader
在步骤14中zhl-1、zhl-2、zhl-3谁显示leader先操作谁，其余两个原follower之后顺序随意
这里是zhl-3是leader，则仅操作zhl-3：
/usr/local/apache-zookeeper-3.5.7-bin/bin/zkServer.sh restart
/usr/local/apache-zookeeper-3.5.7-bin/bin/zkServer.sh status

接下来仅操作zhl-1：
/usr/local/apache-zookeeper-3.5.7-bin/bin/zkServer.sh status

仅操作zhl-2：
/usr/local/apache-zookeeper-3.5.7-bin/bin/zkServer.sh status
这里显示zhl-2变成了leader
结论：原先的leader在restart即故障后，即使重新恢复正常，也不再是leader了，而是由剩下的正常的follower之一继承了leader之位（3台情况下zhl-3不是leader后zhl-2会继承）

16. 测试HA(High Available缩写，指高可用性集群)
关闭zhl-3的Zookeeper 服务，Zookeeper 集群服务仍然可以工作（半数以上服务器有效）
仅操作zhl-3：
/usr/local/apache-zookeeper-3.5.7-bin/bin/zkServer.sh stop
接下来仅操作zhl-1，查看zookeeper集群是否仍能工作
/usr/local/apache-zookeeper-3.5.7-bin/bin/zkServer.sh status

再关闭zhl-2的Zookeeper服务，整个Zookeeper集群服务失效（低于半数服务器失效）
仅操作zhl-2:
/usr/local/apache-zookeeper-3.5.7-bin/bin/zkServer.sh stop
接下来仅操作zhl-1，查看zookeeper集群是否仍能工作
/usr/local/apache-zookeeper-3.5.7-bin/bin/zkServer.sh status
虽然集群失效了，但是仍然开启的服务器用jps能够观察的到

（正常不执行）最后zhl-1、zhl-2、zhl-3一起操作：
/usr/local/apache-zookeeper-3.5.7-bin/bin/zkServer.sh stop
zookeeper的集群部署和测试到此完美结束，下面是zookeeper的使用（建议做一下，节省时间可跳过，直接进行spark，不影响）

2.2 Zookeeper使用（省时间可跳过直接spark，不影响）
2.2.1 Zookeeper shell
1. 
zhl-1、zhl-2、zhl-3一起打开集群，后面无特殊说明仅在zhl-1上操作：
（jps如果显示有了QuorumPeerMain就不执行start）
/usr/local/apache-zookeeper-3.5.7-bin/bin/zkServer.sh start
启动客户端连接 Zookeeper 集群
/usr/local/apache-zookeeper-3.5.7-bin/bin/zkCli.sh
ls /
其中ls查看当前 znode 中所包含的内容

2. 测试shell命令：help列出所有可用命令及用法。
help
ls -s /

①创建普通节点（创建时要写入数据）
create /testroot
ls /
ls -s /testroot
create /testroot/test1
ls /testroot
create /testroot/test2
ls /testroot

②更新和读取节点目录中的数据
set /testroot/test1 &quot;Hello test1&quot;
set /testroot/test2 &quot;Hello test2&quot;
get /testroot 
get /testroot/test1
get /testroot/test2
quit关闭客户端，/usr/local/apache-zookeeper-3.5.7-bin/bin/zkCli.sh + 回车 则是启动客户端

③创建带有序号的znode目录
create -s /testroot/test3
ls /testroot

④监听znode的值的变化，启动另一个客户端（注册一次watch只能监听一次）
get -w /testroot
set /testroot &quot;Hello,h02&quot;

⑤监听znode子目录的变化(注册一次watch只能监听一次)
ls -w /testroot
create -s /testroot/test3

⑥删除znode目录
delete /testroot/test1
ls /testroot

⑦查看znode详细信息
stat /
stat /testroot

⑧递归删除 znode 目录
deleteall /testroot
ls /
quit

（正常不执行）最后zhl-1、zhl-2、zhl-3一起操作：
/usr/local/apache-zookeeper-3.5.7-bin/bin/zkServer.sh stop
这时候zhl-1、zhl-2、zhl-3均备份
zookeeper集群
zookeeper集群和shell使用已完成，API编程未完成（要IDEA环境），下一步spark
2.2.2 Zookeeper API 编程应用（待更新）
(具体安装看视频)输入浏览器下载IntelliJ IDEA:
https://www.jetbrains.com/

网站打不开解决办法：
https://blog.csdn.net/n2278556874/article/details/101477069
破解Ultimate版：https://npegeek.com/
Ultimate激活码（截至2021.2.18，过时了自己去上面网站找）
E70JHCOV2H-eyJsaWNlbnNlSWQiOiJFNzBKSENPVjJIIiwibGljZW5zZWVOYW1lIjoi5bGx5Lic55CG5bel5aSn5a2mIiwiYXNzaWduZWVOYW1lIjoiIiwiYXNzaWduZWVFbWFpbCI6IiIsImxpY2Vuc2VSZXN0cmljdGlvbiI6IkZvciBlZHVjYXRpb25hbCB1c2Ugb25seSIsImNoZWNrQ29uY3VycmVudFVzZSI6ZmFsc2UsInByb2R1Y3RzIjpbeyJjb2RlIjoiSUkiLCJwYWlkVXBUbyI6IjIwMjEtMDItMTgifSx7ImNvZGUiOiJBQyIsInBhaWRVcFRvIjoiMjAyMS0wMi0xOCJ9LHsiY29kZSI6IkRQTiIsInBhaWRVcFRvIjoiMjAyMS0wMi0xOCJ9LHsiY29kZSI6IlBTIiwicGFpZFVwVG8iOiIyMDIxLTAyLTE4In0seyJjb2RlIjoiR08iLCJwYWlkVXBUbyI6IjIwMjEtMDItMTgifSx7ImNvZGUiOiJETSIsInBhaWRVcFRvIjoiMjAyMS0wMi0xOCJ9LHsiY29kZSI6IkNMIiwicGFpZFVwVG8iOiIyMDIxLTAyLTE4In0seyJjb2RlIjoiUlMwIiwicGFpZFVwVG8iOiIyMDIxLTAyLTE4In0seyJjb2RlIjoiUkMiLCJwYWlkVXBUbyI6IjIwMjEtMDItMTgifSx7ImNvZGUiOiJSRCIsInBhaWRVcFRvIjoiMjAyMS0wMi0xOCJ9LHsiY29kZSI6IlBDIiwicGFpZFVwVG8iOiIyMDIxLTAyLTE4In0seyJjb2RlIjoiUk0iLCJwYWlkVXBUbyI6IjIwMjEtMDItMTgifSx7ImNvZGUiOiJXUyIsInBhaWRVcFRvIjoiMjAyMS0wMi0xOCJ9LHsiY29kZSI6IkRCIiwicGFpZFVwVG8iOiIyMDIxLTAyLTE4In0seyJjb2RlIjoiREMiLCJwYWlkVXBUbyI6IjIwMjEtMDItMTgifSx7ImNvZGUiOiJSU1UiLCJwYWlkVXBUbyI6IjIwMjEtMDItMTgifV0sImhhc2giOiIxNjc5MTgwMy8wIiwiZ3JhY2VQZXJpb2REYXlzIjo3LCJhdXRvUHJvbG9uZ2F0ZWQiOmZhbHNlLCJpc0F1dG9Qcm9sb25nYXRlZCI6ZmFsc2V9-qlgtO4xVGHX/r45fIKMaR6B9pWQtucrCYVsz0o00crcAiYN1k/kSMygggYl187B0u0jeXQCe4BmQIItKL79x6NwoPn43inreVhZ88f4+Cbl+V/KGeAYeybon+7YoTs8FY4+31ANW/LwBPxkPnlErxYdQ6oc/k6mnxIOm5Nf8WjKRfYYIl5Bhmdt1gHMGgFsocCcTLLiqDUGEcPj5tUIJXwwYaeKAR3YGXm/P73QpnYR/BcGaodBN3jprQRxsS5Ia5y06rrDAJcPSZuttAFpAit/4o/gq2XzhrjaBCtOMxNzk3XEAT82glTlWQOQx6KnRq6D7WUXzd81g44aP+Dca5Q==-MIIElTCCAn2gAwIBAgIBCTANBgkqhkiG9w0BAQsFADAYMRYwFAYDVQQDDA1KZXRQcm9maWxlIENBMB4XDTE4MTEwMTEyMjk0NloXDTIwMTEwMjEyMjk0NlowaDELMAkGA1UEBhMCQ1oxDjAMBgNVBAgMBU51c2xlMQ8wDQYDVQQHDAZQcmFndWUxGTAXBgNVBAoMEEpldEJyYWlucyBzLnIuby4xHTAbBgNVBAMMFHByb2QzeS1mcm9tLTIwMTgxMTAxMIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAxcQkq+zdxlR2mmRYBPzGbUNdMN6OaXiXzxIWtMEkrJMO/5oUfQJbLLuMSMK0QHFmaI37WShyxZcfRCidwXjot4zmNBKnlyHodDij/78TmVqFl8nOeD5+07B8VEaIu7c3E1N+e1doC6wht4I4+IEmtsPAdoaj5WCQVQbrI8KeT8M9VcBIWX7fD0fhexfg3ZRt0xqwMcXGNp3DdJHiO0rCdU+Itv7EmtnSVq9jBG1usMSFvMowR25mju2JcPFp1+I4ZI+FqgR8gyG8oiNDyNEoAbsR3lOpI7grUYSvkB/xVy/VoklPCK2h0f0GJxFjnye8NT1PAywoyl7RmiAVRE/EKwIDAQABo4GZMIGWMAkGA1UdEwQCMAAwHQYDVR0OBBYEFGEpG9oZGcfLMGNBkY7SgHiMGgTcMEgGA1UdIwRBMD+AFKOetkhnQhI2Qb1t4Lm0oFKLl/GzoRykGjAYMRYwFAYDVQQDDA1KZXRQcm9maWxlIENBggkA0myxg7KDeeEwEwYDVR0lBAwwCgYIKwYBBQUHAwEwCwYDVR0PBAQDAgWgMA0GCSqGSIb3DQEBCwUAA4ICAQAF8uc+YJOHHwOFcPzmbjcxNDuGoOUIP+2h1R75Lecswb7ru2LWWSUMtXVKQzChLNPn/72W0k+oI056tgiwuG7M49LXp4zQVlQnFmWU1wwGvVhq5R63Rpjx1zjGUhcXgayu7+9zMUW596Lbomsg8qVve6euqsrFicYkIIuUu4zYPndJwfe0YkS5nY72SHnNdbPhEnN8wcB2Kz+OIG0lih3yz5EqFhld03bGp222ZQCIghCTVL6QBNadGsiN/lWLl4JdR3lJkZzlpFdiHijoVRdWeSWqM4y0t23c92HXKrgppoSV18XMxrWVdoSM3nuMHwxGhFyde05OdDtLpCv+jlWf5REAHHA201pAU6bJSZINyHDUTB+Beo28rRXSwSh3OUIvYwKNVeoBY+KwOJ7WnuTCUq1meE6GkKc4D/cXmgpOyW/1SmBz3XjVIi/zprZ0zf3qH5mkphtg6ksjKgKjmx1cXfZAAX6wcDBNaCL+Ortep1Dh8xDUbqbBVNBL4jbiL3i3xsfNiyJgaZ5sX7i8tmStEpLbPwvHcByuf59qJhV/bZOl8KqJBETCDJcY6O2aqhTUy+9x93ThKs1GKrRPePrWPluud7ttlgtRveit/pcBrnQcXOl1rHq7ByB8CFAxNotRUYL9IF5n3wJOgkPojMy6jetQA5Ogc8Sm7RG6vg1yow==




3.    Spark
注：无特殊说明只操作zhl-1，而zhl-2、zhl-3不操作。
以下所有步骤后加★意为下面代码可能需要具体修改（加红部分），没检查确认前不要看都不看直接完全copy代码段
zookeeper结束后zhl-1、zhl-2、zhl-3均备份
3.1 Spark部署
1. 从spark官网下载最新版本的安装包。http://spark.apache.org/
cd
wget http://mirror.bit.edu.cn/apache/spark/spark-3.0.0-preview2/spark-3.0.0-preview2-bin-hadoop3.2.tgz

2. 解压安装spark，随后查看
tar -zxvf spark-3.0.0-preview2-bin-hadoop3.2.tgz -C /usr/local/
ls /usr/local/

3.建立软链接
zhl-1、zhl-2、zhl-3一起操作：
ln -s /usr/local/spark-3.0.0-preview2-bin-hadoop3.2 spark
ln -s /usr/local/apache-zookeeper-3.5.7-bin zookeeper
ll
相当于：ls /usr/local/spark-3.0.0-preview2-bin-hadoop3.2/conf/简化为ls spark/conf/
想删除软链接的时候：rm -rf 目标链接
上面zhl-2、zhl-3会爆红，属于正常现象（爆红就是不存在那个目录）
后面步骤会通过scp同步到zhl-2、zhl-3上，爆红会消失

4. ★修改配置文件spark-env.sh和slaves
ls spark/conf/
cp spark/conf/spark-env.sh.template spark/conf/spark-env.sh
cp spark/conf/slaves.template spark/conf/slaves
ls spark/conf/
vim spark/conf/spark-env.sh
export JAVA_HOME=/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.242.b08-0.el7_7.x86_64
export SPARK_WORKER_CORES=1
export SPARK_WORKER_INSTANCES=1 
export SPARK_MASTER_HOST=zhl-1
export SPARK_MASTER_PORT=7077
vim spark/conf/slaves
zhl-1
zhl-2
zhl-3
vim spark/conf/slaves时把localhost删掉
虚拟机内存默认2G+，若比较小（如1G），需要把conf/spark_env.sh 中把 SPARK 的 
WORKER 的工作内存和 executor 内存降低成 900M 或者更低：
（正常不运行）
vim spark/conf/spark-env.sh
export SPARK_EXECUTOR_MEMORY=512M 
export SPARK_WORKER_MEMORY=512M 
export SPARK_DRIVER_MEMORY=512M

5. ★将软件包传输至其他节点上
for i in &#123;2..3&#125;;do scp -r /usr/local/spark-3.0.0-preview2-bin-hadoop3.2 zhl-$i:/usr/local;done
这里把/usr/local/spark-3.0.0-preview2-bin-hadoop3.2改成spark没用……

zhl-2、zhl-3一起操作:
ll
可以发现爆红消失

zhl-1、zhl-2、zhl-3一起操作:
ls spark

6.启动spark 集群(standalone 模式)
下面又仅操作zhl-1：
spark/sbin/start-all.sh
查看
zhl-1、zhl-2、zhl-3一起操作:
jps

★浏览器输入：
http://192.168.1.11:8081/

如果8081打不开，则输入
（正常不运行）
tail -n 100 spark/logs/spark-root-org.apache.spark.deploy.master.Master-1-zhl-1.out
上面tail命令查看日志最后100行，可以看出端口尝试过程，可能是8080，或者8082等等

 
至此spark安装完成

7. 启用 HA 功能（zookeeper必须已经配置完！否则无法进行）
zhl-1、zhl-2、zhl-3一起操作:
vim spark/conf/spark-env.sh
将export SPARK_MASTER_HOST=zhl-1和export SPARK_MASTER_PORT=7077前面加#注释掉，后面加一行
export SPARK_DAEMON_JAVA_OPTS=&quot;-Dspark.deploy.recoveryMode=ZOOKEEPER -Dspark.deploy.zookeeper.url=zhl-1:2181,zhl-2:2181,zhl-3:2181 -Dspark.deploy.zookeeper.dir=/spark&quot;
即最终变成
export JAVA_HOME=/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.242.b08-0.el7_7.x86_64
export SPARK_WORKER_CORES=1
export SPARK_WORKER_INSTANCES=1
#export SPARK_MASTER_HOST=zhl-1
#export SPARK_MASTER_PORT=7077
export SPARK_DAEMON_JAVA_OPTS=&quot;-Dspark.deploy.recoveryMode=ZOOKEEPER -Dspark.deploy.zookeeper.url=zhl-1:2181,zhl-2:2181,zhl-3:2181 -Dspark.deploy.zookeeper.dir=/spark&quot;
下面这两步别跳，spark关了重新启动一下，不然后面这里的
 会只显示[zookeeper]
spark/sbin/stop-all.sh
spark/sbin/start-all.sh

（jps三台均显示QuorumPeerMain则不用）zhl-1、zhl-2、zhl-3一起操作
/usr/local/apache-zookeeper-3.5.7-bin/bin/zkServer.sh start

仅操作zhl-1：
/usr/local/apache-zookeeper-3.5.7-bin/bin/zkCli.sh
ls /
ls /spark -s
quit
其中输入ls /后，必须要同时看到spark和zookeeper才能算成功
 

★仅操作zhl-2：
spark/sbin/start-master.sh
tail -n 100 spark/logs/spark-root-org.apache.spark.deploy.master.Master-1-zhl-2.out
 
通过日志找到了zhl-2使用了8082端口
打开一个浏览器，输入：
http://192.168.1.12:8082/

 
与zhl-1形成了鲜明对比，这里没有一个worker，这里折腾了这么久的意思就是就是要zhl-1是主机，zhl-2是备用主机，然后后面会测试让zhl-1宕机后恢复正常，然后看看zhl-2的反应，进而来检验spark的原理

zhl-1、zhl-2、zhl-3一起操作:
jps

打开第二个浏览器输入：
http://192.168.1.11:8081/

 

★测试zhl-1的master进程宕机（此时zhl-2是备用主机）
jps
kill -9 5424
 kill -9 进程号 要用jps具体查看具体修改

不断刷新浏览器页面，此时zhl-1的页面已经无法打开，zhl-2的要多刷新几次（等一会儿）
 
也就是此时zhl-2（备用主机）完全继承了原先主机zhl-1的功能！所以正常的想法接下来恢复zhl-1（原主机），看看继承的功能会不会还回去

然后重新启动zhl-1的master进程
spark/sbin/start-master.sh
    
也就是说此时原先的备用主机（zhl-2 STANDBY）变成了实质上的主机，而原先的主机（zhl-1 ALIVE）变成了实质上的备用主机，继承的功能并不会随原主机的恢复而还回去！这就是spark集群的特点。

8. ★运行例程蒙特卡洛计算圆周率
spark/bin/spark-submit --master spark://zhl-1:7077,zhl-2:7077,zhl-3:7077 --class org.apache.spark.examples.SparkPi spark/examples/jars/spark-examples_2.12-3.0.0-preview2.jar 10000
10000太大嫌慢了，改小点，运行起来快，但是Π小数点后的精度会下降
 
这是数值为10000时候的结果（其实spark运行起来明显发现比hadoop mapreduce快很多）
这里有这样一组数据供参考：相同的运算次数的情况下，spark用时4.6s，而Hadoop MapReduce 用时35s
有人对上面这段代码或许会问：master和worker有什么区别，运行例程必须要在master上吗？
答：不是这样的。master只是管理作业的和产生运行调度表的，实际运行是在各个worker中excutor进程完成的，不用管哪个master是alive（实质上的主机）了,系统会自动找到alive的master并提交任务的。
    更进一步来讲，上面7. 启用HA功能只是为了测试方便，所以只弄了两台zhl-1、zhl-2，本来这段代码中间应该是--master spark://zhl-1:7077,zhl-2:7077 但是真实情况是会连zhl-3也要写进去的（其中一台是alive，其他全是standby），所有都写的好处在于不去指定，让系统自己找，因为作为客户端大多数时候是没有权限去查看spark的状态的。给一个zk的服务器上下线的例子也是让大家看看zk如何为其他组件提供HA功能的简单原理。

此时观察（即谁是现在实质上的主机master就观察谁，现在是zhl-2）：
http://192.168.1.12:8082/

 
上图是正在运行例程中
 
上图是例程已经运行完毕

★这里示范以下强行设定内存2G执行会怎么样（内存不够）
spark/bin/spark-submit --master spark://zhl-1:7077,zhl-2:7077,zhl-3:7077 --class org.apache.spark.examples.SparkPi --executor-memory 2G spark/examples/jars/spark-examples_2.12-3.0.0-preview2.jar 1000
WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
没有足够的资源，所以报错

到此为止，spark的部署和例程示范完美结束。
（正常下不执行）如果关机则关机前记得：
spark/sbin/stop-all.sh
/usr/local/apache-zookeeper-3.5.7-bin/bin/zkServer.sh stop
上面黄色部分zhl-1、zhl-2、zhl-3一起操作
3.2 Spark使用
3.2.1 Spark shell
1. Spark 本地运行模式(local)
spark/bin/spark-shell
 

ctrl+z退出后仅操作zhl-1：
jps
 
本机运行模式下，使用的是SparkSubmit进程来运行 Spark

2. Spark 集群运行模式（standalone）
spark/bin/spark-shell --master spark://zhl-1:7077,zhl-2:7077,zhl-3:7077
跟本地区别就在于后面多加了--master spark：xxxxx 体现在：
随便选一台比如仅运行zhl-2看看：
jps
 
Standalone集群模式，使用的是CoarseGrainedExecutorBackend进程来运行Spark任务

4.    提交 job
在 后面输入：
sc.textFile(&quot;file:///usr/local/spark-3.0.0-preview2-bin-hadoop3.2/README.md&quot;).flatMap(_.split(&quot; &quot;)).map((_,1)).reduceByKey(_+_).sortBy(_._2,false).collect
如果发现警告WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
就到浏览器 把多余占用的kill掉
 
最后成功运行

然后读取分布式文件系统 HDFS 中的文件（hadoop必须也已经配置完成，否则无法进行）
确保zhl-1、zhl-2、zhl-3已经处于开启状态（第一行若运行3台均操作，其余行若运行只操作zhl-2）：
（一般来讲第三行hadoop还没开启，仅运行第三行，其余正常不运行）
/usr/local/apache-zookeeper-3.5.7-bin/bin/zkServer.sh start
spark/sbin/start-all.sh
/usr/local/hadoop-3.2.1/sbin/start-all.sh

标黄仅操作zhl-2
hdfs dfs -put /root/anaconda-ks.cfg /user/root/
sc.textFile(&quot;hdfs://zhl-1:9000/user/root/anaconda-ks.cfg&quot;).flatMap(_.split(&quot; &quot;)).map((_,1)).reduceByKey(_+_).collect
sc.textFile(&quot;hdfs://zhl-1:9000/user/root/anaconda-ks.cfg&quot;).flatMap(_.split(&quot; &quot;)).map((_,1)).reduceByKey(_+_).sortBy(_._2,false).collect
hdfs dfs -put /root/anaconda-ks.cfg /user/root/将 /root/anaconda-ks.cfg复制到/user/root/路径下
hdfs dfs -rm -r 路径 可以删除对应路径hdfs文件

 
如果报错：java.net.ConnectException: Call From zhl-1/192.168.1.11 to zhl-1:9000 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
那就是还没把hadoop开起

最后关机前关闭（黄色zhl-1、zhl-2、zhl-3均运行）
/usr/local/apache-zookeeper-3.5.7-bin/bin/zkServer.sh stop
spark/sbin/stop-all.sh
/usr/local/hadoop-3.2.1/sbin/stop-all.sh
到此spark完美结束
这时候zhl-1、zhl-2、zhl-3均备份
spark集群
spark集群和shell使用已完成，API编程未完成（要IDEA环境），下一步IDEA
3.2.2 Spark API 编程应用（待更新）
</code></pre>

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/" rel="tag"># 大数据</a>
              <a href="/tags/Hadoop/" rel="tag"># Hadoop</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2020/11/03/YouTube%E6%AD%A6%E6%B1%89%E6%88%98%E5%BD%B9%E8%AF%84%E8%AE%BA/" rel="prev" title="YouTube武汉战役评论">
      <i class="fa fa-chevron-left"></i> YouTube武汉战役评论
    </a></div>
      <div class="post-nav-item">
    <a href="/2020/11/03/%E6%AF%8F%E6%97%A5%E4%B8%80%E9%A2%98-71%E7%BC%96%E8%BE%91%E8%B7%9D%E7%A6%BB/" rel="next" title="每日一题@71编辑距离">
      每日一题@71编辑距离 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="imarktsh"
      src="https://img-blog.csdnimg.cn/2020053010414625.jpg">
  <p class="site-author-name" itemprop="name">imarktsh</p>
  <div class="site-description" itemprop="description">明天一定学</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">146</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">3</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">24</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>



      </div>
        <div class="back-to-top motion-element">
          <i class="fa fa-arrow-up"></i>
          <span>0%</span>
        </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">imarktsh</span>
</div>

    <!-- 网站运行时间的设置 -->
    <span id="timeDate">载入天数...</span>
    <span id="times">载入时分秒...</span>  | It is building your life.
    <script>
        var now = new Date();
        function createtime() {
            var grt= new Date("01/05/2020 00:00:00");//此处修改你的建站时间或者网站上线时间
            now.setTime(now.getTime()+250);
            days = (now - grt ) / 1000 / 60 / 60 / 24; dnum = Math.floor(days);
            hours = (now - grt ) / 1000 / 60 / 60 - (24 * dnum); hnum = Math.floor(hours);
            if(String(hnum).length ==1 ){hnum = "0" + hnum;} minutes = (now - grt ) / 1000 /60 - (24 * 60 * dnum) - (60 * hnum);
            mnum = Math.floor(minutes); if(String(mnum).length ==1 ){mnum = "0" + mnum;}
            seconds = (now - grt ) / 1000 - (24 * 60 * 60 * dnum) - (60 * 60 * hnum) - (60 * mnum);
            snum = Math.round(seconds); if(String(snum).length ==1 ){snum = "0" + snum;}
            document.getElementById("timeDate").innerHTML = "已运行 "+dnum+" 天 ";
            document.getElementById("times").innerHTML = hnum + " 小时 " + mnum + " 分 " + snum + " 秒";
    }
    setInterval("createtime()",250);
    </script><script color="0,0,255" opacity="0.5" zIndex="-1" count="99" src="https://cdn.jsdelivr.net/npm/canvas-nest.js@1/dist/canvas-nest.js"></script>

        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>

<script src="/js/bookmark.js"></script>




  















  

  

</body>
</html>
